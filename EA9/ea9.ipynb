{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data Science - EA9: Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   city_development_index  gender      relevent_experience  \\\n",
      "0                   0.624    Male   No relevent experience   \n",
      "1                   0.926    Male  Has relevent experience   \n",
      "2                   0.920    Male  Has relevent experience   \n",
      "3                   0.624    Male   No relevent experience   \n",
      "4                   0.920  Female  Has relevent experience   \n",
      "\n",
      "  enrolled_university education_level major_discipline experience  \\\n",
      "0       no_enrollment     High School              NaN          5   \n",
      "1       no_enrollment        Graduate             STEM        >20   \n",
      "2       no_enrollment        Graduate             STEM        >20   \n",
      "3    Full time course     High School              NaN          1   \n",
      "4       no_enrollment         Masters             STEM        >20   \n",
      "\n",
      "    company_type last_new_job  training_hours  target  \n",
      "0            NaN        never              21       0  \n",
      "1            NaN           >4              12       0  \n",
      "2  Public Sector           >4              26       0  \n",
      "3            NaN        never              30       1  \n",
      "4            NaN           >4              46       0  \n",
      "   city_development_index  gender      relevent_experience  \\\n",
      "0                   0.624     NaN  Has relevent experience   \n",
      "1                   0.920  Female   No relevent experience   \n",
      "2                   0.767     NaN  Has relevent experience   \n",
      "3                   0.910    Male   No relevent experience   \n",
      "4                   0.624    Male  Has relevent experience   \n",
      "\n",
      "  enrolled_university education_level major_discipline experience  \\\n",
      "0    Full time course        Graduate            Other          3   \n",
      "1       no_enrollment        Graduate             STEM          5   \n",
      "2    Full time course        Graduate             STEM         10   \n",
      "3                 NaN     High School              NaN         10   \n",
      "4    Part time course        Graduate             STEM          3   \n",
      "\n",
      "          company_type last_new_job  training_hours  target  \n",
      "0              Pvt Ltd            1             134       0  \n",
      "1  Early Stage Startup            1              34       1  \n",
      "2              Pvt Ltd            2              90       0  \n",
      "3                  NaN        never              42       0  \n",
      "4              Pvt Ltd            1             198       0  \n"
     ]
    }
   ],
   "source": [
    "# imports for all tasks\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "\n",
    "# Load train_data_data and test dataset\n",
    "train_data = pd.read_csv('./data/aug_train.csv')\n",
    "test_data = pd.read_csv('./data/aug_test.csv')\n",
    "\n",
    "# Display first few rows of the datasets\n",
    "print(train_data.head())\n",
    "print(test_data.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Task 1 - Data clean, imputation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to clean the experience column and last new job column\n",
    "# first make sure that nan-values are reaplced with 0\n",
    "# for experience: replace values bigger than 20 with 21, and values smaller than 1 with 1 and make the column numeric\n",
    "# for last new job:replace values bigger than 4 with 5, and 'never' with 0 and make the column numeric\n",
    "def input_replace_missing_experience_last_new_job(df):\n",
    "    # inpute missing values\n",
    "    df['experience'].fillna('0', inplace=True)\n",
    "    df['last_new_job'].fillna('0', inplace=True)\n",
    "    \n",
    "    # Replace values\n",
    "    df['experience'] = df['experience'].replace('>20', '21').replace('<1', '1').astype(int)\n",
    "    df['last_new_job'] = df['last_new_job'].replace('>4', '5').replace('never', '0').astype(int)\n",
    "    \n",
    "    return df\n",
    "\n",
    "# function to input missing values with it's mode for categorical columns and median for numerical columns\n",
    "def impute_missing_values(df):\n",
    "    for column in df.columns:\n",
    "        if df[column].dtype == 'object':\n",
    "            df[column].fillna(df[column].mode()[0], inplace=True)\n",
    "        else:\n",
    "            df[column].fillna(df[column].median(), inplace=True)\n",
    "    return df\n",
    "\n",
    "# clean the train data with the inpute_replace_missing_experience_last_new_job function\n",
    "train_data = input_replace_missing_experience_last_new_job(train_data)\n",
    "test_data = input_replace_missing_experience_last_new_job(test_data)\n",
    "\n",
    "# add the missing values for train and test data\n",
    "train_data = impute_missing_values(train_data)\n",
    "test_data = impute_missing_values(test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Task 2 - Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Set Evaluation\n",
      "Confusion Matrix:\n",
      "[[1565    0]\n",
      " [   2  533]]\n",
      "Accuracy: 1.00\n",
      "Precision: 1.00\n",
      "Recall: 1.00\n",
      "F1-score: 1.00\n",
      "\n",
      "Test Set Evaluation\n",
      "Confusion Matrix:\n",
      "[[74  4]\n",
      " [16  6]]\n",
      "Accuracy: 0.80\n",
      "Precision: 0.60\n",
      "Recall: 0.27\n",
      "F1-score: 0.37\n"
     ]
    }
   ],
   "source": [
    "# define categorical columns because they need to be encoded before feeding them to the model\n",
    "categorical_columns = ['gender', 'relevent_experience', 'enrolled_university', 'education_level', 'major_discipline', 'company_type']\n",
    "\n",
    "# initialize the OneHotEncoder for categorical columns\n",
    "encoder = OneHotEncoder(drop='first', sparse_output=False)\n",
    "\n",
    "# fit and transform the training data\n",
    "encoded_train = encoder.fit_transform(train_data[categorical_columns])\n",
    "\n",
    "# transform the test data\n",
    "encoded_test = encoder.transform(test_data[categorical_columns])\n",
    "\n",
    "# convert encoded features to pandas dataframe\n",
    "encoded_train_df = pd.DataFrame(encoded_train, columns=encoder.get_feature_names_out(categorical_columns))\n",
    "encoded_test_df = pd.DataFrame(encoded_test, columns=encoder.get_feature_names_out(categorical_columns))\n",
    "\n",
    "# drop original categorical columns and concatenate the encoded dataframe\n",
    "train_data = train_data.drop(categorical_columns, axis=1)\n",
    "test_data = test_data.drop(categorical_columns, axis=1)\n",
    "\n",
    "train_data = pd.concat([train_data, encoded_train_df], axis=1)\n",
    "test_data = pd.concat([test_data, encoded_test_df], axis=1)\n",
    "\n",
    "# define features and target variable\n",
    "X_train = train_data.drop('target', axis=1)\n",
    "y_train = train_data['target']\n",
    "\n",
    "# I decided to got with the random forest classification model, so train the model\n",
    "classification_model = RandomForestClassifier(random_state=42)\n",
    "classification_model.fit(X_train, y_train)\n",
    "\n",
    "# predictions on the training set\n",
    "train_preds = classification_model.predict(X_train)\n",
    "\n",
    "# generate metrics\n",
    "train_conf_matrix = confusion_matrix(y_train, train_preds)\n",
    "train_accuracy = accuracy_score(y_train, train_preds)\n",
    "train_precision = precision_score(y_train, train_preds)\n",
    "train_recall = recall_score(y_train, train_preds)\n",
    "train_f1 = f1_score(y_train, train_preds)\n",
    "\n",
    "print(\"Training Set Evaluation\")\n",
    "print(\"Confusion Matrix:\")\n",
    "print(train_conf_matrix)\n",
    "print(f\"Accuracy: {train_accuracy:.2f}\")\n",
    "print(f\"Precision: {train_precision:.2f}\")\n",
    "print(f\"Recall: {train_recall:.2f}\")\n",
    "print(f\"F1-score: {train_f1:.2f}\")\n",
    "\n",
    "# define features for the test set\n",
    "X_test = test_data.drop('target', axis=1)\n",
    "y_test = test_data['target']\n",
    "\n",
    "# Predictions on the test set\n",
    "test_preds = classification_model.predict(X_test)\n",
    "\n",
    "# Calculate metrics\n",
    "test_conf_matrix = confusion_matrix(y_test, test_preds)\n",
    "test_accuracy = accuracy_score(y_test, test_preds)\n",
    "test_precision = precision_score(y_test, test_preds)\n",
    "test_recall = recall_score(y_test, test_preds)\n",
    "test_f1 = f1_score(y_test, test_preds)\n",
    "\n",
    "print(\"\\nTest Set Evaluation\")\n",
    "print(\"Confusion Matrix:\")\n",
    "print(test_conf_matrix)\n",
    "print(f\"Accuracy: {test_accuracy:.2f}\")\n",
    "print(f\"Precision: {test_precision:.2f}\")\n",
    "print(f\"Recall: {test_recall:.2f}\")\n",
    "print(f\"F1-score: {test_f1:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Comparison of Training and Test Set Results\n",
      "Metric          Training   Test      \n",
      "Accuracy        1.00 0.80\n",
      "Precision       1.00 0.60\n",
      "Recall          1.00 0.27\n",
      "F1-score        1.00 0.37\n"
     ]
    }
   ],
   "source": [
    "# compare training and test set results\n",
    "print(\"\\nComparison of Training and Test Set Results\")\n",
    "print(f\"{'Metric':<15} {'Training':<10} {'Test':<10}\")\n",
    "print(f\"{'Accuracy':<15} {train_accuracy:.2f} {test_accuracy:.2f}\")\n",
    "print(f\"{'Precision':<15} {train_precision:.2f} {test_precision:.2f}\")\n",
    "print(f\"{'Recall':<15} {train_recall:.2f} {test_recall:.2f}\")\n",
    "print(f\"{'F1-score':<15} {train_f1:.2f} {test_f1:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The comparison of metrics between the training and test sets indicates potential overfitting of the model. The significant drop in performance metrics, especially precision, recall, and F1-score, when moving from the training set to the test set, suggests that the model might be memorizing the training data rather than generalizing well to new data.\n",
    "\n",
    "Accuracy: The model achieves perfect accuracy on the training set (1.00) but drops to 0.80 on the test set. This suggests the model is performing well on known data but not as well on unseen data.\n",
    "Precision: The precision drops from 1.00 to 0.60, indicating that the model has a higher rate of false positives on the test set.\n",
    "Recall: The recall drops significantly from 1.00 to 0.27, showing that the model is missing a large number of true positives on the test set.\n",
    "F1-score: The F1-score decreases from 1.00 to 0.37, reinforcing that the modelâ€™s ability to balance precision and recall is much worse on the test set.\n",
    "\n",
    "This problems could be addressed by the performance improvements in the next section (Extra points)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extra points - think about what kind of the method can increase the performance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Better handling of the inbalanced data\n",
    "Resampling is possible, either with oversampling or undersampling or a combination of both. Also the class weights in the random forest classifier could be improved.\n",
    "2. Features\n",
    "Creating new features or transforming existing features to have even more data for the model\n",
    "3. Adavenced algorithms\n",
    "Could use boosted algorithms, like XGBoost. Or could even use Neural Networks if using a large dataset.\n",
    "4. Hyperparameter tuning\n",
    "Could optimize the model's hyperparameters with techniques like grid search, random search of bayesian optimization.\n",
    "5. Model ensembling\n",
    "Cloud use multiple models and combine them to get a better performance\n",
    "\n",
    "Maybe other improvements like cross-validation or regularization could improve the performance further."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
